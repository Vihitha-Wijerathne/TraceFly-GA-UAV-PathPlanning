# -*- coding: utf-8 -*-
"""lidar_hybrid_model_validate.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u1BxE6z_OlFQ_6tn_tfrXrRA6jYCUPWX
"""

!pip install open3d numpy matplotlib tensorflow

import os
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import open3d as o3d
import json
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# ===============================
# ðŸ”¹ 1. Mount Google Drive & Load Trained Model
# ===============================
from google.colab import drive
drive.mount('/content/drive')

data_path = "/content/drive/MyDrive/"
model_load_path = os.path.join(data_path, "trained_lidar_model.pth")
validation_data_path = os.path.join(data_path, "validation_point_cloud.ply")
validation_labels_path = os.path.join(data_path, "validation_labels.txt")

# ===============================
# ðŸ”¹ 2. Load Validation Data
# ===============================
def load_point_cloud(file_path):
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"File not found: {file_path}")
    point_cloud = o3d.io.read_point_cloud(file_path)
    if len(point_cloud.points) == 0:
        raise ValueError(f"Point cloud file is empty or invalid: {file_path}")
    return np.asarray(point_cloud.points)

# Load validation point cloud
val_points = load_point_cloud(validation_data_path)

# ===============================
# ðŸ”¹ 3. Define Neural Network (Ensure it Matches Training Architecture)
# ===============================
import torch.nn as nn

class FeatureExtractor(nn.Module):
    """Feature extraction from point clouds."""
    def __init__(self, input_dim=3, output_dim=512):
        super(FeatureExtractor, self).__init__()
        self.fc1 = nn.Linear(input_dim, 1024)
        self.fc2 = nn.Linear(1024, output_dim)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        return x

class TemporalFusion(nn.Module):
    """LSTM-based Temporal Fusion."""
    def __init__(self, input_dim, hidden_dim, num_layers=1):
        super(TemporalFusion, self).__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_dim, input_dim)

    def forward(self, x):
        out, _ = self.lstm(x.unsqueeze(1))
        out = self.fc(out[:, -1, :])  # Use last LSTM output for classification
        return out

class HybridModel(nn.Module):
    """Final hybrid model integrating PointPillars, CenterPoint & Temporal Fusion."""
    def __init__(self, num_classes=6):  # Ensure correct number of classes
        super(HybridModel, self).__init__()
        self.pointpillars_extractor = FeatureExtractor()
        self.centerpoint_extractor = FeatureExtractor()
        self.fusion_layer = nn.Linear(1024, 256)  # Match training model's fusion layer size
        self.temporal_fusion = TemporalFusion(input_dim=256, hidden_dim=128)
        self.classifier = nn.Linear(256, num_classes)

    def forward(self, x):
        pillars_features = self.pointpillars_extractor(x)
        center_features = self.centerpoint_extractor(x)
        combined_features = torch.cat((pillars_features, center_features), dim=1)
        combined_features = self.fusion_layer(combined_features)
        temporal_features = self.temporal_fusion(combined_features)
        output = self.classifier(temporal_features)
        return output

# ===============================
# ðŸ”¹ 4. Load the Model & Fix State Dict Issues
# ===============================
model = HybridModel()
model.load_state_dict(torch.load(model_load_path), strict=False)  # âœ… Fix for key mismatch issues
model.eval()

# ===============================
# ðŸ”¹ 5. Generate Predictions on Validation Data
# ===============================
val_points_tensor = torch.tensor(val_points, dtype=torch.float32)
with torch.no_grad():
    predictions = model(val_points_tensor).argmax(dim=1).numpy()

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# ===============================
# ðŸ”¹ 6. Load Validation Labels & Compute Metrics
# ===============================
val_labels = np.loadtxt(validation_labels_path, dtype=int)

accuracy = accuracy_score(val_labels, predictions)
precision = precision_score(val_labels, predictions, average="weighted", zero_division=0)
recall = recall_score(val_labels, predictions, average="weighted", zero_division=0)
f1 = f1_score(val_labels, predictions, average="weighted", zero_division=0)

# Print Evaluation Metrics
print("\n **Model Performance Metrics on Validation Data**")
print(f" Accuracy: {accuracy:.4f}")
print(f" Precision: {precision:.4f}")
print(f" Recall: {recall:.4f}")
print(f" F1 Score: {f1:.4f}")

# ===============================
# ðŸ”¹ 7. Save Detected Objects Data to JSON
# ===============================
LABEL_NAMES = {
    0: "Tree",
    1: "Building",
    2: "Vehicle",
    3: "Person",
    4: "Barrier",
    5: "Other Obstacle"
}

detected_objects = []
uav_position = np.array([0, 0, 0])  # UAV starts at (0,0,0)

for i in range(len(predictions)):
    obj_label = predictions[i].item()
    if obj_label in LABEL_NAMES:
        obj_position = val_points[i]
        distance = np.linalg.norm(obj_position - uav_position)

        detected_objects.append({
            "label": LABEL_NAMES[obj_label],
            "position": obj_position.tolist(),
            "distance": round(distance, 2)
        })

# Save to JSON
json_path = "detected_objects.json"
with open(json_path, "w") as f:
    json.dump({"detected_objects": detected_objects}, f, indent=4)

print(f"âœ… Detected objects saved at: {json_path}")

# ===============================
# ðŸ”¹ 8. 3D Visualization of Detected Obstacles
# ===============================
fig = plt.figure(figsize=(8, 6))
ax = fig.add_subplot(111, projection="3d")

# Define colors for different classes
colors = ['r', 'g', 'b', 'y', 'c', 'm']

for i in range(len(val_points)):
    label = predictions[i].item()
    if label < len(colors):  # Ensure index is within range
        ax.scatter(val_points[i, 0], val_points[i, 1], val_points[i, 2], color=colors[label], s=5)

ax.set_xlabel("X")
ax.set_ylabel("Y")
ax.set_zlabel("Z")
ax.set_title("3D Visualization of Detected Obstacles")
plt.show()

# ===============================
# ðŸ”¹ 9. Save & Download JSON + Visualization
# ===============================
fig.savefig("visualization.png")
print(f"âœ… Visualization saved as visualization.png")

from google.colab import files
files.download("detected_objects.json")
files.download("visualization.png")